{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee7ddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original (com erro): c:\\Users\\william.mendes\\OneDrive\\Área de Trabalho\\projects\\pos\\tech_challenge_2_mlet\\.venv\\Lib\\site-packages\\certifi\\cacert.pem\n",
      "Novo caminho seguro criado: C:\\Users\\WILLIA~1.MEN\\AppData\\Local\\Temp\\tmplup0_g_w.pem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import certifi\n",
    "import tempfile\n",
    "\n",
    "caminho_ruim_cert = certifi.where()\n",
    "print(f\"Original (com erro): {caminho_ruim_cert}\")\n",
    "\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix='.pem') as tmp_file:\n",
    "    with open(caminho_ruim_cert, 'rb') as source_file:\n",
    "        shutil.copyfileobj(source_file, tmp_file)\n",
    "    caminho_seguro_cert = tmp_file.name\n",
    "\n",
    "# Se estiver atrás de proxy corporativo (MITM), adicione o CA corporativo aqui (em PEM).\n",
    "# Ex.: defina a env var EXTRA_CA_PEM=c:\\caminho\\corporate_ca.pem\n",
    "extra_ca_path = os.environ.get(\"EXTRA_CA_PEM\")\n",
    "if extra_ca_path and os.path.exists(extra_ca_path):\n",
    "    with open(extra_ca_path, \"rb\") as extra_in, open(caminho_seguro_cert, \"ab\") as out:\n",
    "        out.write(b\"\\n\")\n",
    "        out.write(extra_in.read())\n",
    "    print(f\"CA extra anexado ao bundle: {extra_ca_path}\")\n",
    "\n",
    "print(f\"Novo caminho seguro criado: {caminho_seguro_cert}\")\n",
    "\n",
    "# Requests\n",
    "os.environ['CURL_CA_BUNDLE'] = caminho_seguro_cert\n",
    "os.environ['SSL_CERT_FILE'] = caminho_seguro_cert\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = caminho_seguro_cert\n",
    "\n",
    "import yfinance as yf\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9ff1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tickers_all = ['PETR4.SA', 'VALE3.SA', 'ITUB4.SA', 'BBDC4.SA']\n",
    "# Para debug, use apenas 1 ticker:\n",
    "tickers = ['PETR4.SA']\n",
    "# Para rodar tudo, troque para: tickers = tickers_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b7409a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando pipeline para janela: 2025-12-12 até 2026-01-12 (end exclusivo: 2026-01-13)\n"
     ]
    }
   ],
   "source": [
    "today = datetime.now()\n",
    "\n",
    "# IMPORTANTE (yfinance): `start` é inclusivo e `end` é EXCLUSIVO.\n",
    "# Se você quer incluir D-1 (ontem), passe `end=today`.\n",
    "end_date_obj = today  # exclusivo\n",
    "end_date = end_date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "end_inclusive_obj = today - timedelta(days=1)  # só para exibir no print\n",
    "\n",
    "# Dados dos últimos 1 mês (janela inclusiva)\n",
    "start_date_obj = end_inclusive_obj - relativedelta(months=1)\n",
    "start_date = start_date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Executando pipeline para janela: {start_date} até {end_inclusive_obj.strftime('%Y-%m-%d')} (end exclusivo: {end_date})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e27b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'PETR4.SA' reason: Failed to perform, curl: (60) SSL certificate problem: unable to get local issuer certificate. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n",
      "$PETR4.SA: possibly delisted; no timezone found\n",
      "\n",
      "1 Failed download:\n",
      "['PETR4.SA']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Iniciando Download das ações\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'PETR4.SA' reason: Failed to perform, curl: (60) SSL certificate problem: unable to get local issuer certificate. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n",
      "$PETR4.SA: possibly delisted; no timezone found\n",
      "\n",
      "1 Failed download:\n",
      "['PETR4.SA']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vazio/erro ao baixar: PETR4.SA\n",
      "Falha no diagnóstico HTTP: CertificateVerifyError Failed to perform, curl: (60) SSL certificate problem: unable to get local issuer certificate. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Nenhum ticker foi baixado; verifique o diagnóstico acima. Se for SSL, teste VERIFY_SSL=False só para confirmar a causa.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     67\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_list:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNenhum ticker foi baixado; verifique o diagnóstico acima. Se for SSL, teste VERIFY_SSL=False só para confirmar a causa.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m df_raw = pl.concat(data_list).sort([\u001b[33m\"\u001b[39m\u001b[33mTicker\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     73\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTotal de linhas baixadas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_raw.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Nenhum ticker foi baixado; verifique o diagnóstico acima. Se for SSL, teste VERIFY_SSL=False só para confirmar a causa."
     ]
    }
   ],
   "source": [
    "import time\n",
    "from curl_cffi import requests as crequests\n",
    "\n",
    "data_list = []\n",
    "\n",
    "# yfinance 1.0 usa curl_cffi por baixo; se passar `session`, precisa ser curl_cffi.requests.Session\n",
    "session = crequests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36\"\n",
    "})\n",
    "\n",
    "# Importante: o erro que você estava vendo vem do SSL do libcurl (curl_cffi).\n",
    "# Se você está atrás de proxy corporativo, talvez precise adicionar o CA corporativo ao bundle.\n",
    "VERIFY_SSL = True\n",
    "session.verify = caminho_seguro_cert if VERIFY_SSL else False\n",
    "\n",
    "print(\"\\n>>> Iniciando Download das ações\")\n",
    "\n",
    "for ticker in tickers:\n",
    "    for attempt in (1, 2):\n",
    "        df_y = None\n",
    "        try:\n",
    "            df_y = yf.download(\n",
    "                ticker,\n",
    "                start=start_date,\n",
    "                end=end_date,  # exclusivo\n",
    "                interval=\"1d\",\n",
    "                actions=False,\n",
    "                auto_adjust=False,\n",
    "                repair=True,\n",
    "                progress=False,\n",
    "                threads=False,\n",
    "                timeout=20,\n",
    "                session=session,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            if attempt == 1:\n",
    "                time.sleep(1.0)\n",
    "                continue\n",
    "            print(f\"Erro {ticker}: {type(e).__name__}: {e}\")\n",
    "            df_y = None\n",
    "\n",
    "        if df_y is None or df_y.empty:\n",
    "            if attempt == 1:\n",
    "                time.sleep(1.0)\n",
    "                continue\n",
    "\n",
    "            print(f\"Vazio/erro ao baixar: {ticker}\")\n",
    "            # Diagnóstico rápido (ajuda a detectar 401/403/HTML de proxy/captcha/SSL)\n",
    "            try:\n",
    "                url = f\"http://query1.finance.yahoo.com/v8/finance/chart/{ticker}?range=1mo&interval=1d\"\n",
    "                r = session.get(url, timeout=20)\n",
    "                print(\"Diagnóstico HTTP:\", r.status_code, r.headers.get(\"content-type\"))\n",
    "                print(\"Body (inicio):\", (r.text or \"\")[:200])\n",
    "            except Exception as diag_e:\n",
    "                print(\"Falha no diagnóstico HTTP:\", type(diag_e).__name__, str(diag_e))\n",
    "            break\n",
    "\n",
    "        df_y = df_y.reset_index()\n",
    "        if \"Datetime\" in df_y.columns and \"Date\" not in df_y.columns:\n",
    "            df_y = df_y.rename(columns={\"Datetime\": \"Date\"})\n",
    "        df_y[\"Ticker\"] = ticker\n",
    "\n",
    "        pl_df = pl.from_pandas(df_y)\n",
    "        data_list.append(pl_df)\n",
    "        print(f\"Sucesso: {ticker} ({pl_df.shape[0]} linhas)\")\n",
    "        break\n",
    "\n",
    "if not data_list:\n",
    "    raise RuntimeError(\"Nenhum ticker foi baixado; verifique o diagnóstico acima. Se for SSL, teste VERIFY_SSL=False só para confirmar a causa.\")\n",
    "\n",
    "df_raw = pl.concat(data_list).sort([\"Ticker\", \"Date\"])\n",
    "print(f\"\\nTotal de linhas baixadas: {df_raw.shape[0]}\")\n",
    "print(df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174645a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Transformação (Feature Engineering)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_refined = \u001b[43mdf_raw\u001b[49m.with_columns([\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Cast de data\u001b[39;00m\n\u001b[32m      4\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m).cast(pl.Date).alias(\u001b[33m\"\u001b[39m\u001b[33mdata_pregao\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Lowercase\u001b[39;00m\n\u001b[32m      7\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mTicker\u001b[39m\u001b[33m\"\u001b[39m).str.to_lowercase().alias(\u001b[33m\"\u001b[39m\u001b[33mnome_acao\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Renomeando colunas\u001b[39;00m\n\u001b[32m     10\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mOpen\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mabertura\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     11\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mfechamento\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     12\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     13\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mLow\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     14\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mVolume\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mvolume_negociado\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Média Móvel de 7 dias agrupado por Ticker\u001b[39;00m\n\u001b[32m     17\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m         .rolling_mean(window_size=\u001b[32m7\u001b[39m)\n\u001b[32m     19\u001b[39m         .over(\u001b[33m\"\u001b[39m\u001b[33mTicker\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m         .alias(\u001b[33m\"\u001b[39m\u001b[33mmedia_movel_7d\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Lag 1: O valor de fechamento do dia anterior agrupado por Ticker\u001b[39;00m\n\u001b[32m     23\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m         .shift(\u001b[32m1\u001b[39m)\n\u001b[32m     25\u001b[39m         .over(\u001b[33m\"\u001b[39m\u001b[33mTicker\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m         .alias(\u001b[33m\"\u001b[39m\u001b[33mlag_1d\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# Lag 2: O valor de fechamento de 2 dias atrás agrupado por Ticker\u001b[39;00m\n\u001b[32m     29\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m         .shift(\u001b[32m2\u001b[39m)\n\u001b[32m     31\u001b[39m         .over(\u001b[33m\"\u001b[39m\u001b[33mTicker\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m         .alias(\u001b[33m\"\u001b[39m\u001b[33mlag_2d\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Lag 3: O valor de fechamento de 3 dias atrás agrupado por Ticker\u001b[39;00m\n\u001b[32m     35\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m         .shift(\u001b[32m3\u001b[39m)\n\u001b[32m     37\u001b[39m         .over(\u001b[33m\"\u001b[39m\u001b[33mTicker\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m         .alias(\u001b[33m\"\u001b[39m\u001b[33mlag_3d\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m ])\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Remove linhas com valores nulos\u001b[39;00m\n\u001b[32m     42\u001b[39m df_final = df_refined.drop_nulls()\n",
      "\u001b[31mNameError\u001b[39m: name 'df_raw' is not defined"
     ]
    }
   ],
   "source": [
    "# Transformação (Feature Engineering)\n",
    "if \"df_raw\" not in globals():\n",
    "    raise RuntimeError(\"df_raw não existe. Rode a célula de download e resolva os erros antes de transformar.\")\n",
    "\n",
    "df_refined = df_raw.with_columns([\n",
    "    # Cast de data\n",
    "    pl.col(\"Date\").cast(pl.Date).alias(\"data_pregao\"),\n",
    "\n",
    "    # Lowercase\n",
    "    pl.col(\"Ticker\").str.to_lowercase().alias(\"nome_acao\"),\n",
    "\n",
    "    # Renomeando colunas\n",
    "    pl.col(\"Open\").alias(\"abertura\"),\n",
    "    pl.col(\"Close\").alias(\"fechamento\"),\n",
    "    pl.col(\"High\").alias(\"max\"),\n",
    "    pl.col(\"Low\").alias(\"min\"),\n",
    "    pl.col(\"Volume\").alias(\"volume_negociado\"),\n",
    "    \n",
    "    # Média Móvel de 7 dias agrupado por Ticker\n",
    "    pl.col(\"Close\")\n",
    "        .rolling_mean(window_size=7)\n",
    "        .over(\"Ticker\")\n",
    "        .alias(\"media_movel_7d\"),\n",
    "\n",
    "    # Lag 1: O valor de fechamento do dia anterior agrupado por Ticker\n",
    "    pl.col(\"Close\")\n",
    "        .shift(1)\n",
    "        .over(\"Ticker\")\n",
    "        .alias(\"lag_1d\"),\n",
    "        \n",
    "    # Lag 2: O valor de fechamento de 2 dias atrás agrupado por Ticker\n",
    "    pl.col(\"Close\")\n",
    "        .shift(2)\n",
    "        .over(\"Ticker\")\n",
    "        .alias(\"lag_2d\"),\n",
    "    \n",
    "    # Lag 3: O valor de fechamento de 3 dias atrás agrupado por Ticker\n",
    "    pl.col(\"Close\")\n",
    "        .shift(3)\n",
    "        .over(\"Ticker\")\n",
    "        .alias(\"lag_3d\")\n",
    "])\n",
    "\n",
    "# Remove linhas com valores nulos\n",
    "df_final = df_refined.drop_nulls()\n",
    "\n",
    "# Arredonda valores float para 2 casas decimais\n",
    "df_final = df_final.with_columns(cs.float().round(2))\n",
    "\n",
    "# Remove colunas desnecessárias\n",
    "df_final = df_final.select([\n",
    "    \"data_pregao\", \"nome_acao\", \"abertura\", \"fechamento\", \"max\", \"min\",\n",
    "    \"volume_negociado\", \"media_movel_7d\", \"lag_1d\", \"lag_2d\", \"lag_3d\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af8f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra com Lags e Média Móvel ---\n",
      "shape: (10, 11)\n",
      "┌─────────────┬───────────┬──────────┬────────────┬───┬────────────────┬────────┬────────┬────────┐\n",
      "│ data_pregao ┆ nome_acao ┆ abertura ┆ fechamento ┆ … ┆ media_movel_7d ┆ lag_1d ┆ lag_2d ┆ lag_3d │\n",
      "│ ---         ┆ ---       ┆ ---      ┆ ---        ┆   ┆ ---            ┆ ---    ┆ ---    ┆ ---    │\n",
      "│ date        ┆ str       ┆ f64      ┆ f64        ┆   ┆ f64            ┆ f64    ┆ f64    ┆ f64    │\n",
      "╞═════════════╪═══════════╪══════════╪════════════╪═══╪════════════════╪════════╪════════╪════════╡\n",
      "│ 2025-07-18  ┆ intb3.sa  ┆ 13.76    ┆ 13.35      ┆ … ┆ 13.47          ┆ 13.88  ┆ 13.79  ┆ 13.78  │\n",
      "│ 2025-07-21  ┆ intb3.sa  ┆ 13.4     ┆ 13.62      ┆ … ┆ 13.54          ┆ 13.35  ┆ 13.88  ┆ 13.79  │\n",
      "│ 2025-07-22  ┆ intb3.sa  ┆ 13.61    ┆ 13.35      ┆ … ┆ 13.57          ┆ 13.62  ┆ 13.35  ┆ 13.88  │\n",
      "│ 2025-07-23  ┆ intb3.sa  ┆ 13.35    ┆ 13.72      ┆ … ┆ 13.64          ┆ 13.35  ┆ 13.62  ┆ 13.35  │\n",
      "│ 2025-07-24  ┆ intb3.sa  ┆ 13.72    ┆ 13.65      ┆ … ┆ 13.62          ┆ 13.72  ┆ 13.35  ┆ 13.62  │\n",
      "│ 2025-07-25  ┆ intb3.sa  ┆ 13.61    ┆ 13.9       ┆ … ┆ 13.64          ┆ 13.65  ┆ 13.72  ┆ 13.35  │\n",
      "│ 2025-07-28  ┆ intb3.sa  ┆ 13.91    ┆ 13.61      ┆ … ┆ 13.6           ┆ 13.9   ┆ 13.65  ┆ 13.72  │\n",
      "│ 2025-07-29  ┆ intb3.sa  ┆ 13.67    ┆ 14.12      ┆ … ┆ 13.71          ┆ 13.61  ┆ 13.9   ┆ 13.65  │\n",
      "│ 2025-07-30  ┆ intb3.sa  ┆ 13.76    ┆ 13.44      ┆ … ┆ 13.68          ┆ 14.12  ┆ 13.61  ┆ 13.9   │\n",
      "│ 2025-07-31  ┆ intb3.sa  ┆ 13.3     ┆ 12.96      ┆ … ┆ 13.63          ┆ 13.44  ┆ 14.12  ┆ 13.61  │\n",
      "└─────────────┴───────────┴──────────┴────────────┴───┴────────────────┴────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df_final.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b0bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Agregação Mensal ---\n",
      "shape: (5, 4)\n",
      "┌──────────┬─────────────┬─────────────────────┬────────────────────┐\n",
      "│ Ticker   ┆ data_pregao ┆ volume_mensal_total ┆ preco_medio_mensal │\n",
      "│ ---      ┆ ---         ┆ ---                 ┆ ---                │\n",
      "│ str      ┆ date        ┆ i64                 ┆ f64                │\n",
      "╞══════════╪═════════════╪═════════════════════╪════════════════════╡\n",
      "│ INTB3.SA ┆ 2025-07-01  ┆ 32258900            ┆ 13.54              │\n",
      "│ INTB3.SA ┆ 2025-08-01  ┆ 41764600            ┆ 11.8               │\n",
      "│ INTB3.SA ┆ 2025-09-01  ┆ 49118000            ┆ 11.68              │\n",
      "│ INTB3.SA ┆ 2025-10-01  ┆ 52991000            ┆ 10.65              │\n",
      "│ INTB3.SA ┆ 2025-11-01  ┆ 38471300            ┆ 11.7               │\n",
      "└──────────┴─────────────┴─────────────────────┴────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Agrupamento/Sumarização (mensal)\n",
    "df_agregado = (\n",
    "    df_final\n",
    "    .with_columns(pl.col(\"data_pregao\").dt.truncate(\"1mo\").alias(\"mes\"))\n",
    "    .group_by([\"nome_acao\", \"mes\"])\n",
    "    .agg([\n",
    "        pl.col(\"volume_negociado\").sum().alias(\"volume_mensal_total\"),\n",
    "        pl.col(\"fechamento\").mean().alias(\"preco_medio_mensal\").round(2),\n",
    "    ])\n",
    "    .sort([\"nome_acao\", \"mes\"])\n",
    " )\n",
    "\n",
    "print(\"\\n--- Agregação Mensal ---\")\n",
    "print(df_agregado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c420b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de salvamento local em Parquet (como seria feito no S3)\n",
    "# df_refined.write_parquet(\"dados_refined.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
